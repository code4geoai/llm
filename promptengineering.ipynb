{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27aed687",
   "metadata": {},
   "source": [
    "# Deep Learning.AI\n",
    "## Prompting for Engineers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb013f98",
   "metadata": {},
   "source": [
    "# Principle 1: Write clear and specific instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "932023b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Query Ollama with a reusable function\n",
    "def query_ollama(model: str, prompt: str, stream: bool = False, url: str = \"http://100.117.199.15:11434/api/generate\"):\n",
    "    \"\"\"Send a prompt to Ollama's local server and return the response.\"\"\"\n",
    "    import requests\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": stream\n",
    "    }\n",
    "    response = requests.post(url, json=payload)\n",
    "    if response.ok:\n",
    "        return response.json().get(\"response\")\n",
    "    else:\n",
    "        raise RuntimeError(f\"Ollama error: {response.text}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c391701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama response: The capital of France is **Paris**. \n",
      "\n",
      "It's a global center for art, fashion, gastronomy, and culture. üòä \n",
      "\n",
      "Do you want to know anything more about Paris?\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "model = \"gemma3:4b\"\n",
    "prompt = \"What is the capital of France?\"\n",
    "try:\n",
    "    answer = query_ollama(model, prompt)\n",
    "    print(\"Ollama response:\", answer)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e2b423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To effectively utilize a language model, provide precise and detailed instructions that guide the model towards the desired output, resulting in more relevant and detailed responses.\n"
     ]
    }
   ],
   "source": [
    "#Prompt 1\n",
    "text = f\"\"\"\n",
    "You should express what you want a model to do by providing instructions that are as clear and specific \n",
    "as you can possibly make them. This will guide the model towards the desired output, and reduce the chances \n",
    "of receiving irrelevant or incorrect responses. Don't confuse writing a clear prompt with writing a short prompt. \n",
    "In many cases, longer prompts provide more clarity and context for the model, which can lead to more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = query_ollama(model, prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b31fbf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\n",
      "    \"BookId\": 1,\n",
      "    \"Title\": \"The Beauty Bible: A Complete Guide to Makeup\",\n",
      "    \"Author\": \"Patricia Joyce\",\n",
      "    \"Genre\": \"Makeup & Beauty\"\n",
      "  },\n",
      "  {\n",
      "    \"BookId\": 2,\n",
      "    \"Title\": \"Scarves & Cosmetics: The Ultimate Guide to Makeup\",\n",
      "    \"Author\": \"Laura Nance\",\n",
      "    \"Genre\": \"Makeup & Beauty\"\n",
      "  },\n",
      "  {\n",
      "    \"BookId\": 3,\n",
      "    \"Title\": \"Makeup Styling: A Complete Guide for Every Occasion\",\n",
      "    \"Author\": \"Elizabeth Taylor\",\n",
      "    \"Genre\": \"Makeup & Styling\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt 2\n",
    "text = f\"\"\"Generate me a list of three makeup books titles along with their author and geners. Provide\n",
    "them in json format with the following keys:\n",
    "BookId, Title, Author , Genre\n",
    "  \"\"\"\n",
    "\n",
    "rensponse = query_ollama(model, text)\n",
    "print(rensponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8611e2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Get some water boiling.\n",
      "Step 2: Grab a cup and put a tea bag in it.\n",
      "Step 3: Once the water is hot enough, just pour it over the tea bag.\n",
      "Step 4: Let it sit for a bit so the tea can steep.\n",
      "Step 5: Take out the tea bag.\n",
      "Step 6: If you like, you can add some sugar or milk to taste.\n",
      "Step 7: And that's it! You've got yourself a delicious cup of tea to enjoy.\n"
     ]
    }
   ],
   "source": [
    "# Prompt 3\n",
    "text1 = f\"\"\" Making a cup of tea is easy! First, you need to get some water boiling. While that's happening,  \n",
    "grab a cup and put a tea bag in it. Once the water is hot enough, just pour it over the tea bag. \n",
    "Let it sit for a bit so the tea can steep. After a  few minutes, take out the tea bag. If you  \n",
    "like, you can add some sugar or milk to taste.  And that's it! You've got yourself a delicious  \n",
    "cup of tea to enjoy.\"\"\"\n",
    "\n",
    "prompt = f\"\"\"You will be provided a text delimited by triple backticks. Your task is to extract the sequence of instructions and show in the following format:\n",
    "Step 1:...\n",
    "Step 2: ...\n",
    "\n",
    "\n",
    "Step N: \n",
    "if the text doe not contain steps , Write No step provided.\n",
    "```{text1}```\n",
    " \"\"\"\n",
    "\n",
    "response = query_ollama(model, prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5105c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No steps provided.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt 4\n",
    "text2 = f\"\"\" The sun is shining brightly today, and the birds are singing. It's a beautiful day to go for a walk in the park. The flowers are blooming, and the\n",
    "trees are swaying gently in the breeze. People are out and about, enjoying the lovely weather. Some are having picnics, while others are playing \n",
    "games or simply relaxing on the grass. It's a perfect day to spend time outdoors and appreciate the beauty of nature\"\"\"\n",
    "\n",
    "prompt = f\"\"\"You will be provided a text delimited by triple backticks. Your task is to extract the sequence of instructions and show in the following format:\n",
    "Step 1:...\n",
    "Step 2: ...\n",
    "\n",
    "Step N: \n",
    "if the text doe not contain steps , Write No steps provided.\n",
    "```{text2}```\n",
    " \"\"\"\n",
    "\n",
    "response = query_ollama(model, prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657cf454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<grandparent>: The storm that bends but does not break; the seedling that pushes through the earth; the fire that reforms, stronger than before.\n"
     ]
    }
   ],
   "source": [
    "# Prompt 5 Few Shot Prompting\n",
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest valley flows from a modest spring; the grandest symphony originates from a single note; \n",
    "the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: Teach me about resilience.\n",
    "\"\"\"\n",
    "response = query_ollama(model,prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6786ec9a",
   "metadata": {},
   "source": [
    "# Principle 2: Give the Model to think:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ed49de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here‚Äôs the breakdown of the text as requested:\n",
      "\n",
      "1.  **Summary:** Jack and Jill‚Äôs adventure, initially joyful, resulted in a mishap that caused them to fall down the hill, but their adventurous spirits remained undimmed.\n",
      "\n",
      "2.  **French Translation:** Dans un charmant village, les fr√®res Jack et Jill partent √† la recherche d'eau d'un ruisseau perch√©,\n",
      "    en chantant joyeusement, la chance les fait tomber, mais le plus important, ils tombent ensemble.\n",
      "    Bien que l√©g√®rement √©bouriff√©s, ils reviennent chez eux dans des bras de mer√™tre,\n",
      "    et continuent d'explorer avec plaisir.\n",
      "\n",
      "3.  **List of Names:** Jack, Jill\n",
      "\n",
      "4.  **JSON Object:**\n",
      "```json\n",
      "{\n",
      "  \"french_summary\": \"Dans un charmant village, les fr√®res Jack et Jill partent √† la recherche d'eau d'un ruisseau perch√©, en chantant joyeusement, la chance les fait tomber, mais le plus important, ils tombent ensemble. Bien que l√©g√®rement √©bouriff√©s, ils reviennent chez eux dans des bras de mer√™tre, et continuent d'explorer avec plaisir.\",\n",
      "  \"num_names\": 2\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on a quest to fetch water from a hilltop \n",
    "well. As they climbed, singing joyfully, misfortune struck‚ÄîJack tripped on a stone and tumbled \n",
    "down the hill, with Jill following suit. Though slightly battered, the pair returned home to \n",
    "comforting embraces. Despite the mishap, their adventurous spirits remained undimmed, and they \n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Perform the following actions: \n",
    "1 - Summarize the following text delimited by triple backticks with 1 sentence.\n",
    "2 - Translate the summary into French and use line breaks to avoid scrolling.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the following keys: \n",
    "french_summary, num_names.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = query_ollama(model,prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
